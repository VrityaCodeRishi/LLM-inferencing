services:
  vllm:
    # Driver 580.x supports CUDA 13.0
    # Using cu130-nightly for latest features (nightly builds may be less stable)
    # For stable builds, use: vllm/vllm-openai:cu121
    image: vllm/vllm-openai:cu130-nightly
    command:
      [
        "--model",
        "mistralai/Mistral-7B-Instruct-v0.2",
        "--dtype",
        "bfloat16",
        "--max-model-len",
        "8192"
      ]
    ports:
      - "8000:8000"
    environment:
      - HF_TOKEN=${HF_TOKEN:-}
    volumes:
      - ${HOME}/.cache/huggingface:/root/.cache/huggingface
    ipc: host
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

